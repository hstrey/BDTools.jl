{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f83c5b9f-1b03-43fd-acfa-4e130291c4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2\n",
      "MPS available: True\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split, Dataset, DataLoader, TensorDataset\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "\n",
    "print(torch.__version__)\n",
    "print(f\"MPS available: {torch.backends.mps.is_available()}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c872b86-3a16-43e2-82dd-c486c9c61a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50bd95ec-97e0-422c-8467-e2d3416f072b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = np.load(\"gt_clean_Bay5_101223.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cd093f8-39db-4040-b92c-08d48a641991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NpzFile 'gt_clean_Bay5_101223.npz' with keys: ori64, sim64, ori64means, sim64means, sim64sigmas..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28dd6cb9-b599-4259-acda-56a7c20ba7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori32 = torch.tensor(data_dict[\"ori64\"].transpose((2,1,0))[:,:,:].astype(np.float32))\n",
    "sim32 = torch.tensor(data_dict[\"sim64\"].transpose((2,1,0))[:,:,:].astype(np.float32))\n",
    "ori32means = torch.tensor(data_dict[\"ori64means\"].transpose((2,1,0))[:,:,:].astype(np.float32))\n",
    "sim32means = torch.tensor(data_dict[\"sim64means\"].transpose((2,1,0))[:,:,:].astype(np.float32))\n",
    "ori32sigmas = torch.tensor(data_dict[\"ori64sigmas\"].transpose((2,1,0))[:,:,:].astype(np.float32))\n",
    "sim32sigmas = torch.tensor(data_dict[\"sim64sigmas\"].transpose((2,1,0))[:,:,:].astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e4d9550-a7b5-4b87-920f-901283d5cca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset from input and output\n",
    "dataset = TensorDataset(ori32,sim32,ori32means,sim32means,ori32sigmas,sim32sigmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1c92c7e-6ae3-40f9-b41e-626dced5848f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1948 488\n"
     ]
    }
   ],
   "source": [
    "#Split dataset 80-20\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "batch_size = 8\n",
    "print(train_size, test_size)\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6277f7d8-624d-449a-ba2f-775045b08871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3658)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.corrcoef(torch.stack((torch.flatten(train_dataset[:][0]),torch.flatten(train_dataset[:][1])),dim=0))[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c8f1dc1-05a3-4692-8008-3ba218d48f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3578)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.corrcoef(torch.stack((torch.flatten(test_dataset[:][0]),torch.flatten(test_dataset[:][1])),dim=0))[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "275ee9eb-2b2f-4677-a8b7-10f1dd39506f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.nn.Conv1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 18, 9, padding=\"same\")\n",
    "        self.conv2 = nn.Conv1d(18, 18, 9, padding=\"same\")\n",
    "        self.conv3 = nn.Conv1d(18, 1, 1, padding=\"same\")\n",
    "        self.bn = nn.BatchNorm1d(18)\n",
    "        self.dropout1 = nn.Dropout(0.10)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.sigmoid(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn(x)\n",
    "        x = F.sigmoid(x)\n",
    "\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn(x)\n",
    "        x = F.sigmoid(x)\n",
    "\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn(x)\n",
    "        x = F.sigmoid(x)\n",
    "        \n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn(x)\n",
    "        x = F.sigmoid(x)\n",
    "\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn(x)\n",
    "        x = F.sigmoid(x)\n",
    "        \n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn(x)\n",
    "        x = F.sigmoid(x)\n",
    "\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        output = self.conv3(x)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "807209d1-8ba2-4883-ba29-a4484963d0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15a40328-b2a3-4976-8d3a-0cf982906536",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true,y_pred):\n",
    "    SS_res =  torch.sum(torch.square(y_true - y_pred)) \n",
    "    SS_tot = torch.sum(torch.square(y_true - torch.mean(y_true))) \n",
    "    loss2 =  (1.0 - SS_res/(SS_tot + torch.finfo(torch.float32).eps) )\n",
    "    return -loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ed3adda-4a56-476a-a868-8c15ba96a4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_loss(y_true,y_pred):\n",
    "    c = torch.corrcoef(torch.stack((torch.flatten(y_true),torch.flatten(y_pred)),dim=0))[1,0]\n",
    "    return -c/(1-c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bfcffd0a-f9b9-42c4-981d-f781387eb817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target,_,_,_,_) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = corr_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#        corr = corr_loss(output,target)\n",
    "        if batch_idx == int(train_size/batch_size):\n",
    "            print('Train Epoch: {} \\t\\tCorr: {:.6f}'.format(\n",
    "                epoch, loss.item()/(loss.item()-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "189a1c74-414e-489f-a243-43093ee37d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    corr = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target,_,_,_,_ in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            corr = corr_loss(output,target)\n",
    "    c = corr.item()/(corr.item()-1)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd7ef717-a5ad-4ddd-9300-f3fc5627c544",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8537fa6e-bc25-47d0-a58f-4adf0805ccf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_c = [0.0]\n",
    "best_lr = []\n",
    "best_eps = []\n",
    "best_model = copy.deepcopy(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2d582a65-9466-4b3a-bd0f-7cbadac2e3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 \t\tCorr: 0.528292\n",
      "Train Epoch: 2 \t\tCorr: 0.023587\n",
      "Train Epoch: 3 \t\tCorr: 0.629184\n",
      "Train Epoch: 4 \t\tCorr: 0.293412\n",
      "Train Epoch: 5 \t\tCorr: 0.680213\n",
      "Train Epoch: 6 \t\tCorr: -0.050659\n",
      "Train Epoch: 7 \t\tCorr: 0.200603\n",
      "Train Epoch: 8 \t\tCorr: 0.506370\n",
      "Train Epoch: 9 \t\tCorr: 0.090546\n",
      "Train Epoch: 10 \t\tCorr: 0.470244\n"
     ]
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "lr = 0.03\n",
    "eps = 1e-8\n",
    "optimizer = optim.Adam(model.parameters(),lr = lr, eps=eps)\n",
    "scheduler = StepLR(optimizer, step_size=20, gamma=0.9)\n",
    "for epoch in range(1, 1 + 10):\n",
    "    train(model, device, train_dataloader, optimizer, epoch)\n",
    "    c = test(model, device, test_dataloader)\n",
    "    if c > best_c[-1]:\n",
    "        print(\"Found better model: \",c)\n",
    "        best_c.append(c)\n",
    "        best_lr.append(lr)\n",
    "        best_eps.append(eps)\n",
    "        best_model = copy.deepcopy(model.state_dict())\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "848542b1-2273-41d6-a389-d048e159bc15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4434260311041125"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_c[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c0c1c23b-16e1-49ff-b87a-bab95cbee549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running with lr = 0.040000 and eps = 0.000000\n",
      "Train Epoch: 1 \t\tCorr: 0.505193\n",
      "Train Epoch: 2 \t\tCorr: 0.107766\n",
      "Train Epoch: 3 \t\tCorr: 0.098279\n",
      "Train Epoch: 4 \t\tCorr: -0.066423\n",
      "Train Epoch: 5 \t\tCorr: 0.733172\n",
      "Train Epoch: 6 \t\tCorr: 0.324967\n",
      "Train Epoch: 7 \t\tCorr: 0.105833\n",
      "Train Epoch: 8 \t\tCorr: 0.170344\n",
      "Train Epoch: 9 \t\tCorr: 0.338722\n",
      "Train Epoch: 10 \t\tCorr: 0.705813\n",
      "Train Epoch: 11 \t\tCorr: 0.569215\n",
      "Train Epoch: 12 \t\tCorr: 0.552351\n",
      "Train Epoch: 13 \t\tCorr: -0.142048\n",
      "Train Epoch: 14 \t\tCorr: 0.047246\n",
      "Train Epoch: 15 \t\tCorr: 0.698582\n",
      "Train Epoch: 16 \t\tCorr: -0.026272\n",
      "***************** *************** Found better test model: 0.410404 \n",
      "Train Epoch: 17 \t\tCorr: 0.218262\n",
      "***************** *************** Found better test model: 0.419039 \n",
      "Train Epoch: 18 \t\tCorr: 0.481999\n",
      "Train Epoch: 19 \t\tCorr: 0.592886\n",
      "Train Epoch: 20 \t\tCorr: 0.540452\n",
      "Train Epoch: 21 \t\tCorr: -0.031643\n",
      "Train Epoch: 22 \t\tCorr: 0.532947\n",
      "Train Epoch: 23 \t\tCorr: 0.595526\n",
      "Train Epoch: 24 \t\tCorr: 0.248941\n",
      "Train Epoch: 25 \t\tCorr: 0.031671\n",
      "Train Epoch: 26 \t\tCorr: 0.187113\n",
      "Train Epoch: 27 \t\tCorr: 0.448022\n",
      "Train Epoch: 28 \t\tCorr: 0.659007\n",
      "Train Epoch: 29 \t\tCorr: 0.655742\n",
      "Train Epoch: 30 \t\tCorr: 0.011825\n",
      "Train Epoch: 31 \t\tCorr: -0.164669\n",
      "Train Epoch: 32 \t\tCorr: 0.384606\n",
      "Train Epoch: 33 \t\tCorr: -0.212882\n",
      "Train Epoch: 34 \t\tCorr: 0.248399\n",
      "Train Epoch: 35 \t\tCorr: 0.329478\n",
      "Train Epoch: 36 \t\tCorr: 0.710792\n",
      "Train Epoch: 37 \t\tCorr: 0.544284\n",
      "Train Epoch: 38 \t\tCorr: 0.292547\n",
      "Train Epoch: 39 \t\tCorr: 0.585705\n",
      "Train Epoch: 40 \t\tCorr: 0.184442\n",
      "Train Epoch: 41 \t\tCorr: 0.242296\n",
      "Train Epoch: 42 \t\tCorr: 0.633216\n",
      "Train Epoch: 43 \t\tCorr: -0.011474\n",
      "Train Epoch: 44 \t\tCorr: 0.560505\n",
      "Train Epoch: 45 \t\tCorr: 0.290948\n",
      "Train Epoch: 46 \t\tCorr: 0.766279\n",
      "Train Epoch: 47 \t\tCorr: 0.602821\n",
      "Train Epoch: 48 \t\tCorr: 0.690450\n",
      "Train Epoch: 49 \t\tCorr: 0.038302\n",
      "Train Epoch: 50 \t\tCorr: 0.131485\n",
      "running with lr = 0.040000 and eps = 0.000000\n",
      "Train Epoch: 1 \t\tCorr: 0.054469\n",
      "Train Epoch: 2 \t\tCorr: 0.110765\n",
      "Train Epoch: 3 \t\tCorr: 0.265414\n",
      "Train Epoch: 4 \t\tCorr: 0.208722\n",
      "Train Epoch: 5 \t\tCorr: 0.659768\n",
      "Train Epoch: 6 \t\tCorr: 0.661169\n",
      "Train Epoch: 7 \t\tCorr: 0.059285\n",
      "Train Epoch: 8 \t\tCorr: 0.070281\n",
      "Train Epoch: 9 \t\tCorr: 0.292104\n",
      "Train Epoch: 10 \t\tCorr: 0.342846\n",
      "Train Epoch: 11 \t\tCorr: 0.313243\n",
      "Train Epoch: 12 \t\tCorr: 0.506736\n",
      "Train Epoch: 13 \t\tCorr: 0.202156\n",
      "Train Epoch: 14 \t\tCorr: 0.214540\n",
      "Train Epoch: 15 \t\tCorr: 0.315133\n",
      "Train Epoch: 16 \t\tCorr: 0.175740\n",
      "Train Epoch: 17 \t\tCorr: 0.058638\n",
      "Train Epoch: 18 \t\tCorr: -0.087004\n",
      "Train Epoch: 19 \t\tCorr: 0.488497\n",
      "Train Epoch: 20 \t\tCorr: 0.021603\n",
      "Train Epoch: 21 \t\tCorr: -0.072331\n",
      "Train Epoch: 22 \t\tCorr: 0.195378\n",
      "Train Epoch: 23 \t\tCorr: -0.025212\n",
      "Train Epoch: 24 \t\tCorr: 0.443496\n",
      "Train Epoch: 25 \t\tCorr: 0.065541\n",
      "Train Epoch: 26 \t\tCorr: 0.323498\n",
      "Train Epoch: 27 \t\tCorr: 0.021081\n",
      "Train Epoch: 28 \t\tCorr: 0.725226\n",
      "Train Epoch: 29 \t\tCorr: 0.061878\n",
      "Train Epoch: 30 \t\tCorr: -0.041115\n",
      "Train Epoch: 31 \t\tCorr: 0.746917\n",
      "Train Epoch: 32 \t\tCorr: 0.694135\n",
      "Train Epoch: 33 \t\tCorr: 0.546702\n",
      "Train Epoch: 34 \t\tCorr: 0.551219\n",
      "Train Epoch: 35 \t\tCorr: 0.574547\n",
      "Train Epoch: 36 \t\tCorr: 0.736776\n",
      "Train Epoch: 37 \t\tCorr: 0.129071\n",
      "Train Epoch: 38 \t\tCorr: 0.433070\n",
      "Train Epoch: 39 \t\tCorr: 0.370513\n",
      "Train Epoch: 40 \t\tCorr: 0.523314\n",
      "Train Epoch: 41 \t\tCorr: 0.334494\n",
      "Train Epoch: 42 \t\tCorr: 0.475067\n",
      "Train Epoch: 43 \t\tCorr: 0.526838\n",
      "Train Epoch: 44 \t\tCorr: 0.674279\n",
      "Train Epoch: 45 \t\tCorr: 0.512830\n",
      "Train Epoch: 46 \t\tCorr: 0.522234\n",
      "Train Epoch: 47 \t\tCorr: 0.537863\n",
      "Train Epoch: 48 \t\tCorr: -0.078311\n",
      "Train Epoch: 49 \t\tCorr: 0.677356\n",
      "Train Epoch: 50 \t\tCorr: 0.013949\n",
      "running with lr = 0.040000 and eps = 0.000000\n",
      "Train Epoch: 1 \t\tCorr: 0.068243\n",
      "Train Epoch: 2 \t\tCorr: 0.147608\n",
      "Train Epoch: 3 \t\tCorr: 0.398759\n",
      "Train Epoch: 4 \t\tCorr: -0.052233\n",
      "Train Epoch: 5 \t\tCorr: 0.188997\n",
      "Train Epoch: 6 \t\tCorr: 0.592089\n",
      "Train Epoch: 7 \t\tCorr: 0.635282\n",
      "Train Epoch: 8 \t\tCorr: 0.649117\n",
      "Train Epoch: 9 \t\tCorr: 0.360450\n",
      "Train Epoch: 10 \t\tCorr: 0.177280\n",
      "Train Epoch: 11 \t\tCorr: 0.122657\n",
      "Train Epoch: 12 \t\tCorr: 0.562590\n",
      "Train Epoch: 13 \t\tCorr: 0.507139\n",
      "Train Epoch: 14 \t\tCorr: 0.161110\n",
      "Train Epoch: 15 \t\tCorr: 0.212711\n",
      "Train Epoch: 16 \t\tCorr: 0.558885\n",
      "Train Epoch: 17 \t\tCorr: 0.645854\n",
      "Train Epoch: 18 \t\tCorr: -0.158068\n",
      "Train Epoch: 19 \t\tCorr: -0.159792\n",
      "Train Epoch: 20 \t\tCorr: 0.385322\n",
      "Train Epoch: 21 \t\tCorr: 0.709147\n",
      "Train Epoch: 22 \t\tCorr: 0.437935\n",
      "Train Epoch: 23 \t\tCorr: 0.571856\n",
      "Train Epoch: 24 \t\tCorr: 0.718583\n",
      "Train Epoch: 25 \t\tCorr: 0.020894\n",
      "Train Epoch: 26 \t\tCorr: 0.496377\n",
      "Train Epoch: 27 \t\tCorr: 0.449440\n",
      "Train Epoch: 28 \t\tCorr: 0.048175\n",
      "Train Epoch: 29 \t\tCorr: 0.504999\n",
      "Train Epoch: 30 \t\tCorr: 0.246165\n",
      "Train Epoch: 31 \t\tCorr: 0.194025\n",
      "Train Epoch: 32 \t\tCorr: 0.130238\n",
      "Train Epoch: 33 \t\tCorr: 0.711563\n",
      "Train Epoch: 34 \t\tCorr: 0.384265\n",
      "Train Epoch: 35 \t\tCorr: 0.653317\n",
      "Train Epoch: 36 \t\tCorr: -0.070195\n",
      "Train Epoch: 37 \t\tCorr: 0.166079\n",
      "Train Epoch: 38 \t\tCorr: 0.277703\n",
      "Train Epoch: 39 \t\tCorr: 0.009872\n",
      "Train Epoch: 40 \t\tCorr: 0.716218\n",
      "Train Epoch: 41 \t\tCorr: 0.636784\n",
      "Train Epoch: 42 \t\tCorr: 0.196839\n",
      "Train Epoch: 43 \t\tCorr: 0.558422\n",
      "Train Epoch: 44 \t\tCorr: 0.448252\n",
      "Train Epoch: 45 \t\tCorr: 0.398650\n",
      "Train Epoch: 46 \t\tCorr: 0.585866\n",
      "Train Epoch: 47 \t\tCorr: 0.398185\n",
      "Train Epoch: 48 \t\tCorr: 0.391830\n",
      "Train Epoch: 49 \t\tCorr: 0.676843\n",
      "Train Epoch: 50 \t\tCorr: 0.563539\n",
      "running with lr = 0.050000 and eps = 0.000000\n",
      "Train Epoch: 1 \t\tCorr: 0.374334\n",
      "Train Epoch: 2 \t\tCorr: 0.221457\n",
      "Train Epoch: 3 \t\tCorr: 0.354060\n",
      "Train Epoch: 4 \t\tCorr: 0.290951\n",
      "Train Epoch: 5 \t\tCorr: -0.012087\n",
      "Train Epoch: 6 \t\tCorr: 0.645059\n",
      "Train Epoch: 7 \t\tCorr: -0.009968\n",
      "Train Epoch: 8 \t\tCorr: 0.457978\n",
      "Train Epoch: 9 \t\tCorr: 0.522763\n",
      "Train Epoch: 10 \t\tCorr: 0.232408\n",
      "Train Epoch: 11 \t\tCorr: 0.546317\n",
      "Train Epoch: 12 \t\tCorr: 0.095609\n",
      "Train Epoch: 13 \t\tCorr: 0.647310\n",
      "Train Epoch: 14 \t\tCorr: 0.049419\n",
      "Train Epoch: 15 \t\tCorr: -0.214192\n",
      "Train Epoch: 16 \t\tCorr: 0.456815\n",
      "Train Epoch: 17 \t\tCorr: 0.032451\n",
      "Train Epoch: 18 \t\tCorr: 0.220184\n",
      "Train Epoch: 19 \t\tCorr: 0.554900\n",
      "Train Epoch: 20 \t\tCorr: 0.476396\n",
      "Train Epoch: 21 \t\tCorr: 0.324534\n",
      "Train Epoch: 22 \t\tCorr: 0.633050\n",
      "Train Epoch: 23 \t\tCorr: 0.001855\n",
      "Train Epoch: 24 \t\tCorr: 0.737859\n",
      "Train Epoch: 25 \t\tCorr: 0.171172\n",
      "Train Epoch: 26 \t\tCorr: 0.636485\n",
      "Train Epoch: 27 \t\tCorr: 0.496210\n",
      "Train Epoch: 28 \t\tCorr: 0.488940\n",
      "Train Epoch: 29 \t\tCorr: 0.613089\n",
      "Train Epoch: 30 \t\tCorr: 0.379795\n",
      "Train Epoch: 31 \t\tCorr: 0.079449\n",
      "Train Epoch: 32 \t\tCorr: 0.096978\n",
      "Train Epoch: 33 \t\tCorr: 0.690409\n",
      "Train Epoch: 34 \t\tCorr: -0.151268\n",
      "Train Epoch: 35 \t\tCorr: 0.106625\n",
      "Train Epoch: 36 \t\tCorr: 0.144408\n",
      "Train Epoch: 37 \t\tCorr: 0.547560\n",
      "Train Epoch: 38 \t\tCorr: -0.172800\n",
      "Train Epoch: 39 \t\tCorr: 0.485703\n",
      "Train Epoch: 40 \t\tCorr: 0.064306\n",
      "Train Epoch: 41 \t\tCorr: 0.724088\n",
      "Train Epoch: 42 \t\tCorr: 0.648382\n",
      "Train Epoch: 43 \t\tCorr: -0.227186\n",
      "Train Epoch: 44 \t\tCorr: 0.730367\n",
      "Train Epoch: 45 \t\tCorr: 0.086432\n",
      "Train Epoch: 46 \t\tCorr: -0.145428\n",
      "Train Epoch: 47 \t\tCorr: 0.101516\n",
      "Train Epoch: 48 \t\tCorr: 0.322857\n",
      "Train Epoch: 49 \t\tCorr: -0.002241\n",
      "Train Epoch: 50 \t\tCorr: 0.660513\n",
      "running with lr = 0.050000 and eps = 0.000000\n",
      "Train Epoch: 1 \t\tCorr: 0.354315\n",
      "Train Epoch: 2 \t\tCorr: -0.098233\n",
      "Train Epoch: 3 \t\tCorr: 0.598747\n",
      "Train Epoch: 4 \t\tCorr: -0.059563\n",
      "Train Epoch: 5 \t\tCorr: 0.296499\n",
      "Train Epoch: 6 \t\tCorr: 0.207805\n",
      "Train Epoch: 7 \t\tCorr: 0.641329\n",
      "Train Epoch: 8 \t\tCorr: 0.163379\n",
      "Train Epoch: 9 \t\tCorr: 0.492428\n",
      "Train Epoch: 10 \t\tCorr: 0.324068\n",
      "Train Epoch: 11 \t\tCorr: 0.521940\n",
      "Train Epoch: 12 \t\tCorr: 0.519437\n",
      "Train Epoch: 13 \t\tCorr: 0.279820\n",
      "Train Epoch: 14 \t\tCorr: 0.603735\n",
      "Train Epoch: 15 \t\tCorr: 0.728734\n",
      "Train Epoch: 16 \t\tCorr: 0.525800\n",
      "Train Epoch: 17 \t\tCorr: 0.002262\n",
      "Train Epoch: 18 \t\tCorr: 0.439532\n",
      "Train Epoch: 19 \t\tCorr: -0.013358\n",
      "Train Epoch: 20 \t\tCorr: 0.229488\n",
      "Train Epoch: 21 \t\tCorr: 0.292205\n",
      "Train Epoch: 22 \t\tCorr: 0.205747\n",
      "Train Epoch: 23 \t\tCorr: 0.077980\n",
      "Train Epoch: 24 \t\tCorr: 0.079107\n",
      "Train Epoch: 25 \t\tCorr: -0.155778\n",
      "Train Epoch: 26 \t\tCorr: 0.650302\n",
      "Train Epoch: 27 \t\tCorr: 0.150587\n",
      "Train Epoch: 28 \t\tCorr: 0.199415\n",
      "Train Epoch: 29 \t\tCorr: 0.672706\n",
      "Train Epoch: 30 \t\tCorr: 0.540540\n",
      "Train Epoch: 31 \t\tCorr: -0.000491\n",
      "Train Epoch: 32 \t\tCorr: 0.718267\n",
      "Train Epoch: 33 \t\tCorr: 0.534838\n",
      "Train Epoch: 34 \t\tCorr: 0.165979\n",
      "Train Epoch: 35 \t\tCorr: 0.638807\n",
      "Train Epoch: 36 \t\tCorr: 0.468229\n",
      "Train Epoch: 37 \t\tCorr: -0.011925\n",
      "Train Epoch: 38 \t\tCorr: -0.115415\n",
      "Train Epoch: 39 \t\tCorr: 0.010097\n",
      "Train Epoch: 40 \t\tCorr: 0.188424\n",
      "Train Epoch: 41 \t\tCorr: 0.608270\n",
      "Train Epoch: 42 \t\tCorr: 0.536772\n",
      "Train Epoch: 43 \t\tCorr: 0.012163\n",
      "Train Epoch: 44 \t\tCorr: 0.261990\n",
      "Train Epoch: 45 \t\tCorr: 0.253453\n",
      "Train Epoch: 46 \t\tCorr: 0.098460\n",
      "Train Epoch: 47 \t\tCorr: 0.386730\n",
      "Train Epoch: 48 \t\tCorr: 0.566574\n",
      "Train Epoch: 49 \t\tCorr: 0.064227\n",
      "Train Epoch: 50 \t\tCorr: 0.029686\n",
      "running with lr = 0.050000 and eps = 0.000000\n",
      "Train Epoch: 1 \t\tCorr: 0.449756\n",
      "Train Epoch: 2 \t\tCorr: 0.455555\n",
      "Train Epoch: 3 \t\tCorr: 0.103806\n",
      "Train Epoch: 4 \t\tCorr: 0.721647\n",
      "Train Epoch: 5 \t\tCorr: 0.289237\n",
      "Train Epoch: 6 \t\tCorr: 0.636225\n",
      "Train Epoch: 7 \t\tCorr: 0.312452\n",
      "Train Epoch: 8 \t\tCorr: 0.700935\n",
      "Train Epoch: 9 \t\tCorr: 0.029581\n",
      "Train Epoch: 10 \t\tCorr: 0.694126\n",
      "Train Epoch: 11 \t\tCorr: -0.014188\n",
      "Train Epoch: 12 \t\tCorr: 0.014669\n",
      "Train Epoch: 13 \t\tCorr: 0.359545\n",
      "Train Epoch: 14 \t\tCorr: 0.590405\n",
      "Train Epoch: 15 \t\tCorr: 0.056797\n",
      "Train Epoch: 16 \t\tCorr: 0.347537\n",
      "Train Epoch: 17 \t\tCorr: 0.248275\n",
      "Train Epoch: 18 \t\tCorr: 0.080769\n",
      "Train Epoch: 19 \t\tCorr: -0.059852\n",
      "Train Epoch: 20 \t\tCorr: 0.517652\n",
      "Train Epoch: 21 \t\tCorr: 0.465404\n",
      "Train Epoch: 22 \t\tCorr: 0.130223\n",
      "Train Epoch: 23 \t\tCorr: -0.002137\n",
      "Train Epoch: 24 \t\tCorr: 0.501161\n",
      "Train Epoch: 25 \t\tCorr: 0.101735\n",
      "Train Epoch: 26 \t\tCorr: 0.105891\n",
      "Train Epoch: 27 \t\tCorr: 0.444928\n",
      "Train Epoch: 28 \t\tCorr: 0.556788\n",
      "Train Epoch: 29 \t\tCorr: 0.511418\n",
      "Train Epoch: 30 \t\tCorr: 0.708480\n",
      "Train Epoch: 31 \t\tCorr: 0.454602\n",
      "Train Epoch: 32 \t\tCorr: 0.601969\n",
      "Train Epoch: 33 \t\tCorr: -0.118073\n",
      "Train Epoch: 34 \t\tCorr: 0.503192\n",
      "Train Epoch: 35 \t\tCorr: 0.096433\n",
      "Train Epoch: 36 \t\tCorr: 0.278817\n",
      "Train Epoch: 37 \t\tCorr: 0.728339\n",
      "Train Epoch: 38 \t\tCorr: 0.626967\n",
      "Train Epoch: 39 \t\tCorr: 0.604862\n",
      "Train Epoch: 40 \t\tCorr: -0.032707\n",
      "Train Epoch: 41 \t\tCorr: 0.121605\n",
      "Train Epoch: 42 \t\tCorr: 0.560469\n",
      "Train Epoch: 43 \t\tCorr: 0.386285\n",
      "Train Epoch: 44 \t\tCorr: 0.660910\n",
      "Train Epoch: 45 \t\tCorr: 0.290601\n",
      "Train Epoch: 46 \t\tCorr: 0.652999\n",
      "Train Epoch: 47 \t\tCorr: -0.332255\n",
      "Train Epoch: 48 \t\tCorr: 0.587169\n",
      "Train Epoch: 49 \t\tCorr: 0.472427\n",
      "Train Epoch: 50 \t\tCorr: 0.024485\n",
      "running with lr = 0.060000 and eps = 0.000000\n",
      "Train Epoch: 1 \t\tCorr: 0.448558\n",
      "Train Epoch: 2 \t\tCorr: 0.682498\n",
      "Train Epoch: 3 \t\tCorr: 0.436856\n",
      "Train Epoch: 4 \t\tCorr: 0.543555\n",
      "Train Epoch: 5 \t\tCorr: 0.112644\n",
      "Train Epoch: 6 \t\tCorr: 0.748583\n",
      "Train Epoch: 7 \t\tCorr: 0.186296\n",
      "Train Epoch: 8 \t\tCorr: 0.688718\n",
      "Train Epoch: 9 \t\tCorr: 0.577229\n",
      "Train Epoch: 10 \t\tCorr: -0.060704\n",
      "Train Epoch: 11 \t\tCorr: 0.684835\n",
      "Train Epoch: 12 \t\tCorr: 0.621717\n",
      "Train Epoch: 13 \t\tCorr: 0.109536\n",
      "Train Epoch: 14 \t\tCorr: 0.488079\n",
      "Train Epoch: 15 \t\tCorr: -0.108887\n",
      "Train Epoch: 16 \t\tCorr: 0.583914\n",
      "Train Epoch: 17 \t\tCorr: 0.639915\n",
      "Train Epoch: 18 \t\tCorr: 0.245223\n",
      "Train Epoch: 19 \t\tCorr: 0.133717\n",
      "Train Epoch: 20 \t\tCorr: 0.196958\n",
      "Train Epoch: 21 \t\tCorr: 0.624426\n",
      "Train Epoch: 22 \t\tCorr: 0.502426\n",
      "Train Epoch: 23 \t\tCorr: 0.590929\n",
      "Train Epoch: 24 \t\tCorr: 0.291229\n",
      "Train Epoch: 25 \t\tCorr: 0.679173\n",
      "Train Epoch: 26 \t\tCorr: -0.128813\n",
      "Train Epoch: 27 \t\tCorr: 0.522995\n",
      "Train Epoch: 28 \t\tCorr: -0.084633\n",
      "Train Epoch: 29 \t\tCorr: 0.465106\n",
      "Train Epoch: 30 \t\tCorr: -0.165788\n",
      "Train Epoch: 31 \t\tCorr: -0.102141\n",
      "Train Epoch: 32 \t\tCorr: 0.195728\n",
      "Train Epoch: 33 \t\tCorr: 0.546975\n",
      "Train Epoch: 34 \t\tCorr: 0.263920\n",
      "Train Epoch: 35 \t\tCorr: 0.659487\n",
      "Train Epoch: 36 \t\tCorr: 0.432360\n",
      "Train Epoch: 37 \t\tCorr: 0.519403\n",
      "Train Epoch: 38 \t\tCorr: 0.593459\n",
      "Train Epoch: 39 \t\tCorr: 0.403464\n",
      "Train Epoch: 40 \t\tCorr: 0.096691\n",
      "Train Epoch: 41 \t\tCorr: 0.761972\n",
      "Train Epoch: 42 \t\tCorr: -0.054817\n",
      "Train Epoch: 43 \t\tCorr: -0.046523\n",
      "Train Epoch: 44 \t\tCorr: -0.054279\n",
      "Train Epoch: 45 \t\tCorr: 0.185841\n",
      "Train Epoch: 46 \t\tCorr: -0.023628\n",
      "Train Epoch: 47 \t\tCorr: 0.645267\n",
      "Train Epoch: 48 \t\tCorr: 0.374022\n",
      "Train Epoch: 49 \t\tCorr: 0.234988\n",
      "Train Epoch: 50 \t\tCorr: 0.130422\n",
      "running with lr = 0.060000 and eps = 0.000000\n",
      "Train Epoch: 1 \t\tCorr: 0.329305\n",
      "Train Epoch: 2 \t\tCorr: -0.058399\n",
      "Train Epoch: 3 \t\tCorr: 0.352823\n",
      "Train Epoch: 4 \t\tCorr: 0.523100\n",
      "Train Epoch: 5 \t\tCorr: 0.543170\n",
      "Train Epoch: 6 \t\tCorr: 0.683795\n",
      "Train Epoch: 7 \t\tCorr: -0.018267\n",
      "Train Epoch: 8 \t\tCorr: 0.687017\n",
      "Train Epoch: 9 \t\tCorr: 0.497566\n",
      "Train Epoch: 10 \t\tCorr: 0.706621\n",
      "Train Epoch: 11 \t\tCorr: 0.065879\n",
      "Train Epoch: 12 \t\tCorr: 0.535664\n",
      "Train Epoch: 13 \t\tCorr: 0.204638\n",
      "Train Epoch: 14 \t\tCorr: 0.142912\n",
      "Train Epoch: 15 \t\tCorr: 0.073446\n",
      "Train Epoch: 16 \t\tCorr: 0.429950\n",
      "Train Epoch: 17 \t\tCorr: 0.560886\n",
      "Train Epoch: 18 \t\tCorr: 0.743542\n",
      "Train Epoch: 19 \t\tCorr: 0.051370\n",
      "Train Epoch: 20 \t\tCorr: 0.111776\n",
      "Train Epoch: 21 \t\tCorr: 0.259179\n",
      "Train Epoch: 22 \t\tCorr: 0.217701\n",
      "Train Epoch: 23 \t\tCorr: 0.640704\n",
      "Train Epoch: 24 \t\tCorr: 0.071651\n",
      "Train Epoch: 25 \t\tCorr: -0.057085\n",
      "Train Epoch: 26 \t\tCorr: 0.613840\n",
      "Train Epoch: 27 \t\tCorr: 0.629974\n",
      "Train Epoch: 28 \t\tCorr: 0.503632\n",
      "Train Epoch: 29 \t\tCorr: 0.526213\n",
      "Train Epoch: 30 \t\tCorr: 0.511519\n",
      "Train Epoch: 31 \t\tCorr: 0.384681\n",
      "Train Epoch: 32 \t\tCorr: 0.001748\n",
      "Train Epoch: 33 \t\tCorr: 0.530113\n",
      "Train Epoch: 34 \t\tCorr: 0.528984\n",
      "Train Epoch: 35 \t\tCorr: 0.588627\n",
      "Train Epoch: 36 \t\tCorr: -0.039716\n",
      "Train Epoch: 37 \t\tCorr: 0.433421\n",
      "Train Epoch: 38 \t\tCorr: 0.549609\n",
      "Train Epoch: 39 \t\tCorr: 0.590657\n",
      "Train Epoch: 40 \t\tCorr: 0.024113\n",
      "Train Epoch: 41 \t\tCorr: 0.460978\n",
      "Train Epoch: 42 \t\tCorr: 0.431105\n",
      "Train Epoch: 43 \t\tCorr: -0.367491\n",
      "Train Epoch: 44 \t\tCorr: 0.618043\n",
      "Train Epoch: 45 \t\tCorr: 0.121135\n",
      "Train Epoch: 46 \t\tCorr: 0.168836\n",
      "Train Epoch: 47 \t\tCorr: 0.629844\n",
      "Train Epoch: 48 \t\tCorr: 0.499869\n",
      "Train Epoch: 49 \t\tCorr: 0.254854\n",
      "Train Epoch: 50 \t\tCorr: -0.097459\n",
      "running with lr = 0.060000 and eps = 0.000000\n",
      "Train Epoch: 1 \t\tCorr: 0.042162\n",
      "Train Epoch: 2 \t\tCorr: 0.060350\n",
      "Train Epoch: 3 \t\tCorr: 0.170406\n",
      "Train Epoch: 4 \t\tCorr: 0.217564\n",
      "Train Epoch: 5 \t\tCorr: 0.583080\n",
      "Train Epoch: 6 \t\tCorr: 0.476502\n",
      "Train Epoch: 7 \t\tCorr: 0.724869\n",
      "Train Epoch: 8 \t\tCorr: 0.600317\n",
      "Train Epoch: 9 \t\tCorr: -0.153589\n",
      "Train Epoch: 10 \t\tCorr: 0.092118\n",
      "Train Epoch: 11 \t\tCorr: 0.515739\n",
      "Train Epoch: 12 \t\tCorr: 0.460344\n",
      "Train Epoch: 13 \t\tCorr: 0.094204\n",
      "Train Epoch: 14 \t\tCorr: 0.018285\n",
      "Train Epoch: 15 \t\tCorr: -0.054451\n",
      "Train Epoch: 16 \t\tCorr: 0.661959\n",
      "Train Epoch: 17 \t\tCorr: 0.690554\n",
      "Train Epoch: 18 \t\tCorr: 0.758274\n",
      "Train Epoch: 19 \t\tCorr: -0.155127\n",
      "Train Epoch: 20 \t\tCorr: 0.660656\n",
      "Train Epoch: 21 \t\tCorr: 0.224348\n",
      "Train Epoch: 22 \t\tCorr: -0.005173\n",
      "Train Epoch: 23 \t\tCorr: -0.121183\n",
      "Train Epoch: 24 \t\tCorr: 0.581937\n",
      "Train Epoch: 25 \t\tCorr: 0.588960\n",
      "Train Epoch: 26 \t\tCorr: -0.047340\n",
      "Train Epoch: 27 \t\tCorr: 0.314910\n",
      "Train Epoch: 28 \t\tCorr: 0.633910\n",
      "Train Epoch: 29 \t\tCorr: 0.247114\n",
      "Train Epoch: 30 \t\tCorr: 0.014337\n",
      "Train Epoch: 31 \t\tCorr: 0.704214\n",
      "Train Epoch: 32 \t\tCorr: 0.574648\n",
      "Train Epoch: 33 \t\tCorr: 0.796667\n",
      "Train Epoch: 34 \t\tCorr: -0.230073\n",
      "Train Epoch: 35 \t\tCorr: 0.545621\n",
      "Train Epoch: 36 \t\tCorr: 0.700755\n",
      "Train Epoch: 37 \t\tCorr: 0.448826\n",
      "Train Epoch: 38 \t\tCorr: -0.168580\n",
      "Train Epoch: 39 \t\tCorr: 0.731306\n",
      "Train Epoch: 40 \t\tCorr: -0.213251\n",
      "Train Epoch: 41 \t\tCorr: 0.615935\n",
      "Train Epoch: 42 \t\tCorr: 0.547732\n",
      "Train Epoch: 43 \t\tCorr: -0.196592\n",
      "Train Epoch: 44 \t\tCorr: 0.728148\n",
      "Train Epoch: 45 \t\tCorr: 0.065502\n",
      "Train Epoch: 46 \t\tCorr: 0.511175\n",
      "Train Epoch: 47 \t\tCorr: 0.248979\n",
      "Train Epoch: 48 \t\tCorr: 0.756094\n",
      "Train Epoch: 49 \t\tCorr: 0.404465\n",
      "Train Epoch: 50 \t\tCorr: 0.585721\n"
     ]
    }
   ],
   "source": [
    "# do this over and over\n",
    "for lr in [0.04,0.05,0.06]:\n",
    "    for eps in [0.0,1e-8,1e-7]:\n",
    "        model = Net().to(device)\n",
    "        print(\"running with lr = {:.6f} and eps = {:.6f}\".format(lr,eps))\n",
    "        optimizer = optim.Adam(model.parameters(),lr = lr, eps=eps)\n",
    "        scheduler = StepLR(optimizer, step_size=20, gamma=0.9)\n",
    "        train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "        for epoch in range(1, 1 + 50):\n",
    "            train(model, device, train_dataloader, optimizer, epoch)\n",
    "            c = test(model, device, test_dataloader)\n",
    "            if c > best_c[-1]:\n",
    "                print(\"***************** *************** Found better test model: {:.6f} \".format(c))\n",
    "                best_c.append(c)\n",
    "                best_lr.append(lr)\n",
    "                best_eps.append(eps)\n",
    "                best_model = copy.deepcopy(model.state_dict())\n",
    "            scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "020743ba-e7fc-442a-a82a-1caed91a3780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44217669115921787"
      ]
     },
     "execution_count": 621,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_c[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "94868a82-74f6-4f8b-bc6c-87463d4d5a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.060000000000000005,\n",
       " 0.060000000000000005,\n",
       " 0.060000000000000005,\n",
       " 0.060000000000000005,\n",
       " 0.060000000000000005,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.060000000000000005,\n",
       " 0.060000000000000005,\n",
       " 0.060000000000000005,\n",
       " 0.060000000000000005,\n",
       " 0.060000000000000005,\n",
       " 0.060000000000000005,\n",
       " 0.060000000000000005,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04,\n",
       " 0.04]"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "c3e949d2-261f-4e7b-b7c7-593cb401fd55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1e-07,\n",
       " 1e-07,\n",
       " 1e-07,\n",
       " 1e-07,\n",
       " 1e-07,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1e-07,\n",
       " 1e-07,\n",
       " 1e-07,\n",
       " 1e-07,\n",
       " 1e-07,\n",
       " 1e-07,\n",
       " 1e-07,\n",
       " 1e-08,\n",
       " 1e-08,\n",
       " 1e-08,\n",
       " 1e-08,\n",
       " 1e-08]"
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "f264b7af-7630-4662-9feb-9d3a4f84a3fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv1.weight',\n",
       "              tensor([[[ -7.6829,  -5.1831,  -4.6984,  11.0466,  10.7742,   1.8159,   2.5917,\n",
       "                         -3.6361,   2.6898]],\n",
       "              \n",
       "                      [[  4.1333,   0.2688,  -2.9713,  -6.9882, -11.8796,   2.3708,   5.3326,\n",
       "                         -0.9624,  -5.3388]],\n",
       "              \n",
       "                      [[  5.3304,   0.4318,  -2.9044,  -8.8970,   1.7081,  11.3247,  -2.7253,\n",
       "                         -6.9710,  -3.2048]],\n",
       "              \n",
       "                      [[  4.6007,   4.3738,  -0.5227,   2.2120,   6.0605,   6.2686,  -3.8337,\n",
       "                         -3.7178,  -0.6072]],\n",
       "              \n",
       "                      [[  2.6091,   1.5694,  -0.5482,  -4.8140,  -2.8100,  -1.3248,  -2.2218,\n",
       "                         -0.8914,   4.1590]],\n",
       "              \n",
       "                      [[ -4.3274,   2.5563,   1.5808,  -1.7534,  -7.2680,  -5.3195,  15.1455,\n",
       "                          3.3599,  -0.2593]],\n",
       "              \n",
       "                      [[ -2.6539,   5.7885,  10.1281,  -3.7610,  -7.2827,   6.5932,   5.7836,\n",
       "                         -3.0492,  -4.7449]],\n",
       "              \n",
       "                      [[ -3.8217,  -2.1847,  -0.3160, -10.4236,   1.7001,   3.9873,  -2.5752,\n",
       "                         -1.1775,   0.3994]],\n",
       "              \n",
       "                      [[ -5.7230,  -0.4971,   2.0589,   1.2336,  -2.7994,  -0.3099,   0.6541,\n",
       "                         -0.7688,  -4.0553]],\n",
       "              \n",
       "                      [[  5.4649,  -7.1320,  -8.8835,  -2.1188,   5.4307,   2.2396,  -0.0967,\n",
       "                          2.0229,   6.6728]],\n",
       "              \n",
       "                      [[  0.5344,  -1.3532,  -1.4467,   1.9237,   2.2097,  -7.4565,  -3.1765,\n",
       "                         -3.6711,  -8.5309]],\n",
       "              \n",
       "                      [[  0.8838,  -1.3132,  -1.8935,  -3.3244,  -0.8100, -18.1785,  -3.8505,\n",
       "                          3.6125,   3.7847]],\n",
       "              \n",
       "                      [[  1.7142,   3.0938,   0.5725,   1.0487,   4.6208,   6.2726,   0.2929,\n",
       "                          1.1961,   3.6938]],\n",
       "              \n",
       "                      [[-12.3126, -10.2391,   8.3437,   6.7077,   2.5118,  -1.5133,  -1.7336,\n",
       "                          3.5869,   0.9235]],\n",
       "              \n",
       "                      [[  0.5525,   1.1722,  -0.7247,  -0.9072,   0.7105,  -0.0206,  -1.1875,\n",
       "                          1.4294,   4.6861]],\n",
       "              \n",
       "                      [[ -6.9414,  -0.5817,  -3.8839,   1.9250,   0.6784,   8.5215,   0.2346,\n",
       "                         -4.8450,  -7.9436]],\n",
       "              \n",
       "                      [[ -5.9497,  -6.1958,  -0.2167,   0.9870,   3.0292,   0.5008,   2.2377,\n",
       "                         -1.9425,  -4.6235]],\n",
       "              \n",
       "                      [[  0.7506,   5.9607,   5.7721,   1.8982,   2.9353,  -2.0639,  -1.4148,\n",
       "                         -0.9187,  -2.2665]]], device='mps:0')),\n",
       "             ('conv1.bias',\n",
       "              tensor([  1.3547,  -8.3070,   0.5418, -12.9607, -20.3277,   0.9794,   0.2251,\n",
       "                      -11.1987, -22.0562,   2.1153, -14.5292,  -0.4547, -14.9470,  -0.3759,\n",
       "                      -23.9675,  -2.2032,  18.8203, -13.9806], device='mps:0')),\n",
       "             ('conv2.weight',\n",
       "              tensor([[[-17.4951, -10.9307,  -0.1400,  ...,   1.9714,   5.9776,  17.9814],\n",
       "                       [  4.9779,   1.0613,  -3.2250,  ...,   1.7738,   6.6577,   9.8738],\n",
       "                       [ -0.2253,  -1.9455,   2.1924,  ...,   2.7390,   3.8744,   5.7130],\n",
       "                       ...,\n",
       "                       [ -2.7602,  -6.2252,  -6.7087,  ...,  -2.1846,  -0.4095,  -0.5194],\n",
       "                       [  7.2251,   6.1192,   5.2183,  ...,   4.1617,  -0.7851,  -8.0462],\n",
       "                       [ -1.6199,  -0.2145,  -1.2280,  ...,   2.8545,   2.7400,   4.3016]],\n",
       "              \n",
       "                      [[ -1.9880,  -1.5717,   0.9049,  ...,  -6.9399,   2.4157,   9.9433],\n",
       "                       [ -5.2569,  -8.7112,  -8.5619,  ...,   4.1814,   6.7521,   5.2596],\n",
       "                       [ -5.1020,  -7.0379, -11.8158,  ...,  -0.6975,   1.8212,  -0.1802],\n",
       "                       ...,\n",
       "                       [  6.5310,   1.7155,  -1.8732,  ...,   3.1771,   1.8988,   1.1203],\n",
       "                       [ -5.2863,  -4.0234,   0.3804,  ...,  -5.7776,  -5.8963,  -5.2225],\n",
       "                       [  3.6267,   5.7471,   3.5645,  ...,   4.2003,   4.3360,   6.3628]],\n",
       "              \n",
       "                      [[ -3.5509,  -8.3777,  -8.2416,  ...,  -0.5774,   1.9509,   0.6926],\n",
       "                       [  0.3991,  -4.7754,   1.7537,  ...,   7.7519,   4.2507,  -3.1133],\n",
       "                       [ -4.8999,  -2.5847,   2.9831,  ...,   1.7613,   2.1672,  -0.8044],\n",
       "                       ...,\n",
       "                       [  2.6087,  -0.2435,  -1.1829,  ...,  -2.8212,  -5.0387,   0.5842],\n",
       "                       [  3.2488,  -1.5366,   2.8521,  ...,  -7.3531,  -0.1159,  -0.0295],\n",
       "                       [  4.2612,   4.7539,   4.9036,  ...,  -3.1279,  -1.4559,  -2.4322]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[  2.3652,  -2.3993,  -3.2187,  ...,   0.4888,   1.6225,   3.3047],\n",
       "                       [  0.1814,   2.8995,   4.2037,  ...,   1.6319,   1.2001,   1.7909],\n",
       "                       [ -1.4871,   1.2878,   1.6385,  ...,   0.9295,  -1.3923,  -1.0870],\n",
       "                       ...,\n",
       "                       [ -0.5775,  -1.9174,  -4.5121,  ...,   1.4759,   2.0828,   4.4337],\n",
       "                       [  3.6436,   0.8591,  -5.6187,  ...,  -0.1706,  -2.2364,  -3.3855],\n",
       "                       [ -6.3471,  -8.4255,  -7.6238,  ..., -13.1058, -14.9125, -13.8547]],\n",
       "              \n",
       "                      [[  1.6816,  -3.1360,  -5.0281,  ...,   1.3891,   3.0750,   8.2572],\n",
       "                       [  3.5349,   4.0821,   3.4624,  ...,  -2.1371,   3.1105,   3.4234],\n",
       "                       [ -7.6027,  -1.7684,  -1.2248,  ...,   0.3776,  -2.0003,   0.2955],\n",
       "                       ...,\n",
       "                       [  2.3038,   3.8504,   5.9458,  ...,  -1.1911,   1.3596,   9.7449],\n",
       "                       [ -3.1575,  -0.1381,   1.9074,  ...,  -8.1644,  -6.3576,  -1.1815],\n",
       "                       [  1.9747,  -2.7573,  -1.4036,  ...,   6.0494,   0.6947,   3.1228]],\n",
       "              \n",
       "                      [[ -0.9050,   0.4444,   1.9270,  ...,   1.4322,   1.4456,   4.7461],\n",
       "                       [ -0.4820,   0.4462,  -1.1861,  ..., -13.4214, -10.7786,  -3.9429],\n",
       "                       [ -3.9198,  -1.0312,  -1.8562,  ...,  -9.5640, -10.1380, -12.1200],\n",
       "                       ...,\n",
       "                       [  4.8279,   4.3374,   5.4011,  ...,   3.5077,   4.5364,   5.4465],\n",
       "                       [  1.0266,   2.3130,   1.1484,  ...,  -1.2325,  -4.5751,  -9.8339],\n",
       "                       [ -1.5353,   3.0946,   2.7792,  ...,  -3.1539,   3.4438,   9.2095]]],\n",
       "                     device='mps:0')),\n",
       "             ('conv2.bias',\n",
       "              tensor([-0.0057, -0.0163,  0.0223, -0.0988,  0.0626, -0.0074, -0.0836,  0.0487,\n",
       "                       0.0024,  0.0715,  0.0290,  0.0344,  0.0659, -0.0409, -0.0546, -0.0561,\n",
       "                      -0.0988,  0.1017], device='mps:0')),\n",
       "             ('conv3.weight',\n",
       "              tensor([[[ 2.6956],\n",
       "                       [-5.1177],\n",
       "                       [ 1.0477],\n",
       "                       [ 3.8915],\n",
       "                       [-3.0938],\n",
       "                       [ 8.2283],\n",
       "                       [-8.0353],\n",
       "                       [ 4.0136],\n",
       "                       [10.6616],\n",
       "                       [-3.3678],\n",
       "                       [-7.0444],\n",
       "                       [ 1.9522],\n",
       "                       [ 3.4593],\n",
       "                       [-4.8709],\n",
       "                       [-3.0299],\n",
       "                       [13.8966],\n",
       "                       [-2.9964],\n",
       "                       [-6.1865]]], device='mps:0')),\n",
       "             ('conv3.bias', tensor([0.0217], device='mps:0')),\n",
       "             ('bn.weight',\n",
       "              tensor([2.2973, 1.9107, 4.0574, 2.9292, 2.6384, 1.5088, 2.2014, 1.8240, 1.0365,\n",
       "                      2.8272, 2.3528, 3.7516, 3.1031, 1.7614, 2.0749, 1.1856, 2.5017, 2.1759],\n",
       "                     device='mps:0')),\n",
       "             ('bn.bias',\n",
       "              tensor([-3.4401, -3.7743, -1.5418, -4.9866, -4.2849, -4.1538, -4.7007, -3.4147,\n",
       "                      -4.3138, -4.6745, -5.4328, -1.8574, -4.3985, -3.6748, -4.1259, -4.0684,\n",
       "                      -4.0432, -3.8515], device='mps:0')),\n",
       "             ('bn.running_mean',\n",
       "              tensor([  8.8290, -24.8599, -13.7499, -16.9757, -39.2504, -37.0266, -13.5744,\n",
       "                       34.5451,  34.7738, -20.1081, -24.6470,   1.3914,   5.9107,  -1.1700,\n",
       "                      -18.9724, -12.2739, -18.5296, -27.9502], device='mps:0')),\n",
       "             ('bn.running_var',\n",
       "              tensor([ 554.5905, 1094.3444,  952.5250,  690.9940,  904.3311,  760.8513,\n",
       "                       877.4814,  849.8208,  799.0186, 1064.4467,  714.1734,  860.2750,\n",
       "                       630.8712,  524.9481,  927.2099,  465.1751,  712.6193,  704.2551],\n",
       "                     device='mps:0')),\n",
       "             ('bn.num_batches_tracked', tensor(55632, device='mps:0'))])"
      ]
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "0971360a-77ef-4ca9-8e36-5d8686793833",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model, \"bd_clean_Bay5model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "193ef91d-bf46-4d6a-b62c-d511025b5823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv1d(1, 18, kernel_size=(9,), stride=(1,), padding=same)\n",
       "  (conv2): Conv1d(18, 18, kernel_size=(9,), stride=(1,), padding=same)\n",
       "  (conv3): Conv1d(18, 1, kernel_size=(1,), stride=(1,), padding=same)\n",
       "  (bn): BatchNorm1d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout1): Dropout(p=0.1, inplace=False)\n",
       "  (dropout2): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "model_saved = Net()\n",
    "model_saved.load_state_dict(torch.load(\"bd_clean_Bay5model.pt\", weights_only=True))\n",
    "model_saved.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "2c52db83-3c21-43af-89da-0f9e22c65163",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ori, test_sim, test_ori_mean, test_sim_mean, test_ori_sigmas, test_sim_sigmas = next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "d5823e5d-1878-4d35-8564-95c8e1ed9bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cleaned = model_saved(test_ori)\n",
    "test_cleaned_denorm = test_cleaned * test_ori_sigmas + test_ori_mean\n",
    "test_ori_denorm = test_ori * test_ori_sigmas + test_ori_mean\n",
    "test_sim_denorm = test_sim * test_sim_sigmas + test_sim_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "cb4ea1df-c3dc-4951-b9bd-6b98c848f07d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3657)"
      ]
     },
     "execution_count": 628,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.corrcoef(torch.stack((torch.flatten(test_ori),torch.flatten(test_sim)),dim=0))[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "id": "09729db8-4722-491c-bd65-1a3a10634237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4279)"
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.corrcoef(torch.stack((torch.flatten(test_ori_denorm),torch.flatten(test_sim_denorm)),dim=0))[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "id": "afae39b6-85f0-4046-9af8-ab567716badd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4422, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.corrcoef(torch.stack((torch.flatten(test_cleaned),torch.flatten(test_sim)),dim=0))[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "id": "e0c260de-4e5b-4bd5-9ddb-50aa7c2a3cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5116, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.corrcoef(torch.stack((torch.flatten(test_cleaned_denorm),torch.flatten(test_sim_denorm)),dim=0))[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "id": "35510a00-68e1-4854-905d-05ea7cea9708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3642)"
      ]
     },
     "execution_count": 632,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.corrcoef(torch.stack((torch.flatten(dataset[:][0]),torch.flatten(dataset[:][1])),dim=0))[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "id": "53c86fa9-ba27-42de-bcef-d6aaaa752b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4366, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 633,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.corrcoef(torch.stack((torch.flatten(model_saved(dataset[:][0])),torch.flatten(dataset[:][1])),dim=0))[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "id": "54b4a87e-36ec-4527-8ad3-0b7b904890b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1700847689362865"
      ]
     },
     "execution_count": 634,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.4279-0.3657)/0.3657"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90adbd53-86d4-400a-9ffd-6c3036ef45f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
